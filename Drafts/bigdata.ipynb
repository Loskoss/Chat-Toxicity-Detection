{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonflag = []\n",
    "df_flag =[]\n",
    "df_nonflag = pd.concat(\n",
    "    [pd.read_parquet(x) for x in glob('/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/chats/chats_nonflag_*.parquet')],\n",
    "    ignore_index=True)\n",
    "df_flag = pd.concat(\n",
    "    [pd.read_parquet(x) for x in glob('/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/chats/chats_flagged_*.parquet')],\n",
    "    ignore_index=True)\n",
    "\n",
    "ytdata = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/DirtyWords.csv\")\n",
    "ytdata = ytdata.drop(columns=[\"language\",'id'])\n",
    "ytdata['spam'] = 1\n",
    "ytdata = ytdata.rename(columns={\"word\": \"body\"})\n",
    "yt1 = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/Youtube01-Psy.csv\")\n",
    "yt1 = yt1.drop(columns=['COMMENT_ID', 'AUTHOR', 'DATE',])\n",
    "yt1 = yt1.rename(columns={\"CLASS\": \"spam\", \"CONTENT\": \"body\"})\n",
    "yt2 = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/Youtube02-KatyPerry.csv\")\n",
    "yt2 = yt2.drop(columns=['COMMENT_ID', 'AUTHOR', 'DATE',])\n",
    "yt2 = yt2.rename(columns={\"CLASS\": \"spam\", \"CONTENT\": \"body\"})\n",
    "yt3 = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/Youtube03-LMFAO.csv\")\n",
    "yt3 = yt3.drop(columns=['COMMENT_ID', 'AUTHOR', 'DATE',])\n",
    "yt3 = yt3.rename(columns={\"CLASS\": \"spam\", \"CONTENT\": \"body\"})\n",
    "yt4 = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/Youtube05-Shakira.csv\")\n",
    "yt4 = yt4.drop(columns=['COMMENT_ID', 'AUTHOR', 'DATE',])\n",
    "yt4 = yt4.rename(columns={\"CLASS\": \"spam\", \"CONTENT\": \"body\"})\n",
    "yt5 = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/Youtube04-Eminem.csv\")\n",
    "yt5 = yt5.drop(columns=['COMMENT_ID', 'AUTHOR', 'DATE',])\n",
    "yt5 = yt5.rename(columns={\"CLASS\": \"spam\", \"CONTENT\": \"body\"})\n",
    "ytprof = pd.read_csv(\"/mnt/22A63810A637E2C9/Code/Twitch-Spam-detection/Data/profanity_en.csv\")\n",
    "\n",
    "\n",
    "df = pd.concat([df_flag, df_nonflag], axis=0, ignore_index=True)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6263746</th>\n",
       "      <td>めんどくせぇなｗ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988033</th>\n",
       "      <td>あまりに強すぎた</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85982</th>\n",
       "      <td>@プランプ I agree with Coco that the best course o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978432</th>\n",
       "      <td>kusojapan timeeee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845092</th>\n",
       "      <td>聴診器ですかｗ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      body  spam\n",
       "6263746                                           めんどくせぇなｗ     0\n",
       "4988033                                           あまりに強すぎた     0\n",
       "85982    @プランプ I agree with Coco that the best course o...     1\n",
       "3978432                                  kusojapan timeeee     0\n",
       "845092                                             聴診器ですかｗ     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_labels = ['hidden','deleted']\n",
    "df['spam'] = df['label'].apply(lambda x: 1 if x in spam_labels else 0)\n",
    "df=df.drop(columns=['label'])\n",
    "dataframes = [ytdata, yt1, yt2, yt3, yt4, yt5]\n",
    "c_df=pd.concat(dataframes,ignore_index=True)\n",
    "X_train, X_tes, y_train, y_test = train_test_split(\n",
    "    c_df['body'], c_df['spam'], test_size=0.2, random_state=69)\n",
    "randomized_df = df.sample(frac=1.0, random_state=64)\n",
    "randomized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data :  4155\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data : \", len(c_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['body', 'spam'], dtype='object')\n",
      "Index(['body', 'spam'], dtype='object')\n",
      "Index(['body', 'spam'], dtype='object')\n",
      "Index(['body', 'spam'], dtype='object')\n",
      "Index(['body', 'spam'], dtype='object')\n",
      "Index(['body', 'spam'], dtype='object')\n",
      "Index(['body', 'spam'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(ytdata.columns)\n",
    "print(yt3.columns)\n",
    "print(yt1.columns)\n",
    "print(df.columns)\n",
    "print(yt2.columns)\n",
    "print(yt4.columns)\n",
    "print(yt5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.76       199\n",
      "           1       0.89      0.99      0.94       632\n",
      "\n",
      "    accuracy                           0.91       831\n",
      "   macro avg       0.93      0.81      0.85       831\n",
      "weighted avg       0.91      0.91      0.90       831\n",
      "\n",
      "Naive Bayes model accuracy(in %): 90.61371841155234\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_tes)\n",
    "SClassifier=MultinomialNB()\n",
    "SClassifier.fit(X_train_tfidf,y_train)\n",
    "pred =SClassifier.predict(X_test_tfidf)\n",
    "report = classification_report(y_test,pred)\n",
    "print(\"Spam Classification Report:\")\n",
    "print(report)\n",
    "print(\"Naive Bayes model accuracy(in %):\",accuracy_score(y_test, pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86       199\n",
      "           1       0.94      0.98      0.96       632\n",
      "\n",
      "    accuracy                           0.94       831\n",
      "   macro avg       0.93      0.89      0.91       831\n",
      "weighted avg       0.94      0.94      0.93       831\n",
      "\n",
      "SVM model accuracy(in %): 93.62214199759326\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC(kernel='linear') \n",
    "# poly was the lowest with 86% linear is highest then sigmoid and then rbf.\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test_tfidf)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "print(f\"Accuracy: {accuracy_svm:.2f}\")\n",
    "print(report_svm)\n",
    "print(\"SVM model accuracy(in %):\",accuracy_score(y_test, y_pred_svm)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       199\n",
      "           1       0.95      0.97      0.96       632\n",
      "\n",
      "    accuracy                           0.94       831\n",
      "   macro avg       0.92      0.91      0.92       831\n",
      "weighted avg       0.94      0.94      0.94       831\n",
      "\n",
      "Random Forest model accuracy(in %): 94.1034897713598\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100) \n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test_tfidf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
    "print(report_rf)\n",
    "print(\"Random Forest model accuracy(in %):\",accuracy_score(y_test, y_pred_rf)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73       199\n",
      "           1       0.89      0.99      0.94       632\n",
      "\n",
      "    accuracy                           0.90       831\n",
      "   macro avg       0.92      0.79      0.83       831\n",
      "weighted avg       0.90      0.90      0.89       831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier = LogisticRegression()\n",
    "logistic_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = logistic_classifier.predict(X_test_tfidf)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(f\"Accuracy: {accuracy_lr:.2f}\")\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76063355])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfv = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "comment1 = ['go kill yourself']\n",
    "comment1_vect = tfidf_vectorizer.transform(comment1)\n",
    "rf_classifier.predict_proba(comment1_vect)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "\n",
    "# Constants\n",
    "WINDOW_SIZE = 600\n",
    "GRID_SIZE = 50\n",
    "AMPLITUDE = 0.1\n",
    "DAMPING = 0.99\n",
    "UPDATE_INTERVAL = 10  # milliseconds\n",
    "\n",
    "# Global variables\n",
    "grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=float)\n",
    "velocity = np.zeros((GRID_SIZE, GRID_SIZE), dtype=float)\n",
    "\n",
    "def init():\n",
    "    glClearColor(0.0, 0.0, 0.0, 1.0)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, WINDOW_SIZE, 0, WINDOW_SIZE)\n",
    "\n",
    "def update_wave(value):\n",
    "    global grid, velocity\n",
    "    new_grid = np.zeros((GRID_SIZE, GRID_SIZE), dtype=float)\n",
    "    new_velocity = np.zeros((GRID_SIZE, GRID_SIZE), dtype=float)\n",
    "\n",
    "    for i in range(1, GRID_SIZE - 1):\n",
    "        for j in range(1, GRID_SIZE - 1):\n",
    "            new_velocity[i][j] = (\n",
    "                velocity[i][j] * DAMPING\n",
    "                + (grid[i + 1][j] + grid[i - 1][j] + grid[i][j + 1] + grid[i][j - 1]) * 0.25\n",
    "                - grid[i][j]\n",
    "            )\n",
    "            new_grid[i][j] = grid[i][j] + new_velocity[i][j]\n",
    "\n",
    "    grid, velocity = new_grid, new_velocity\n",
    "    glutPostRedisplay()\n",
    "    glutTimerFunc(UPDATE_INTERVAL, update_wave, 0)\n",
    "\n",
    "def display():\n",
    "    glClear(GL_COLOR_BUFFER_BIT)\n",
    "    glColor3f(1.0, 1.0, 1.0)\n",
    "    glBegin(GL_POINTS)\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            glVertex2f(i * (WINDOW_SIZE / GRID_SIZE), j * (WINDOW_SIZE / GRID_SIZE) + grid[i][j])\n",
    "    glEnd()\n",
    "    glFlush()\n",
    "\n",
    "def main():\n",
    "    glutInit(sys.argv)\n",
    "    glutInitDisplayMode(GLUT_SINGLE | GLUT_RGB)\n",
    "    glutInitWindowSize(WINDOW_SIZE, WINDOW_SIZE)\n",
    "    glutCreateWindow(b\"Wave Simulator\")\n",
    "    glutDisplayFunc(display)\n",
    "    glutTimerFunc(UPDATE_INTERVAL, update_wave, 0)\n",
    "    init()\n",
    "    glutMainLoop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
